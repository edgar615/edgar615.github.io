---
layout: post
title: 缓存-第一部分
date: 2019-06-13
categories:
    - 缓存
comments: true
permalink: cache-1.html
---

# 为什么要用缓存

对于一个服务其性能瓶颈往往都在MySQL。我们在创建表的时候，并不会未所有的字段创建索引，这意味着如果我们需要读取非缓存数据就要从磁盘拿数据。这个过程至少需要十几毫秒的时间。而缓存往往是基于内存的，这要比DB读数据快两个数量级。这是我们用缓存的根本原因原因。

## 高性能

假设这么个场景，有个操作，一个请求过来，耗时 600ms 操作 MySQL查出来一个结果，但是这个结果可能接下来几个小时都不会变了，或者变了也可以不会立即反馈给用户。那么此时咋办？

将折腾 600ms 查出来的结果放入缓存里，一个 key 对应一个 value，下次查找时不经过 MySQL，直接从缓存里通过一个 key 查出来一个 value，2ms 搞定，性能提升 300 倍。

所以对于一些需要复杂操作耗时查出来的结果，确定后面不怎么变化，但是有很多读请求，直接将查询出来的结果放在缓存中，后面直接读缓存就好。

## 高并发

MySQL 数据库对于高并发来说天然支持不好，MySQL 单机支撑到 2000QPS 也开始容易报警了。

所以若是系统高峰期一秒钟有1万个请求，那么一个 MySQL 单机绝对会死掉。这个时候就只能上缓存，把很多数据放入缓存，别放入 MySQL。缓存功能简单，说白了就是 key-value 式操作，单机支撑的并发量一秒可达几万十几万，单机承载并发量是 MySQL 单机的几十倍。

# 缓存
缓存也是一个数据模型对象，那么必然有它的一些特征：

- **命中率** 命中率=返回正确结果数/请求缓存次数，命中率问题是缓存中的一个非常重要的问题，它是衡量缓存有效性的重要指标。命中率越高，表明缓存的使用率越高。
- **最大元素（或最大空间）** 缓存中可以存放的最大元素的数量，一旦缓存中元素数量超过这个值（或者缓存数据所占空间超过其最大支持空间），那么将会触发缓存启动清空策略根据不同的场景合理的设置最大元素值往往可以一定程度上提高缓存的命中率，从而更有效的时候缓存。
- **清空策略** 如上描述，缓存的存储空间有限制，当缓存空间被用满时，如何保证在稳定服务的同时有效提升命中率？这就由缓存清空策略来处理，设计适合自身数据特征的清空策略能有效提升命中率

## 清空策略

**FIFO(first in first out)**

先进先出策略，最先进入缓存的数据在缓存空间不够的情况下（超出最大元素限制）会被优先被清除掉，以腾出新的空间接受新的数据。策略算法主要比较缓存元素的创建时间。在数据实效性要求场景下可选择该类策略，优先保障最新数据可用。

**LFU(less frequently used)**

最少使用策略，无论是否过期，根据元素的被使用次数判断，清除使用次数较少的元素释放空间。策略算法主要比较元素的hitCount（命中次数）。在保证高频数据有效性场景下，可选择这类策略。

**LRU(least recently used)**

最近最少使用策略，无论是否过期，根据元素最后一次被使用的时间戳，清除最远使用时间戳的元素释放空间。策略算法主要比较元素最近一次被get使用时间。在热点数据场景下较适用，优先保证热点数据的有效性。

LRU和LFU的区别。LFU算法是根据在一段时间里数据项被使用的次数选择出最少使用的数据项，即根据使用次数的差异来决定。而LRU是根据使用时间的差异来决定的。

## 本地缓存
本地缓存指的是在应用中的缓存组件，其最大的优点是应用和cache是在同一个进程内部，请求缓存非常快速，没有过多的网络开销等，在单应用不需要集群支持或者集群情况下各节点无需互相通知的场景下使用本地缓存较合适；同时，它的缺点也是应为缓存跟应用程序耦合，多个应用程序无法直接的共享缓存，各应用或集群的各节点都需要维护自己的单独缓存，对内存是一种浪费。

## 分布式缓存
分布式缓存：指的是与应用分离的缓存组件或服务，其最大的优点是自身就是一个独立的应用，与本地应用隔离，多个应用可直接的共享缓存。

# 使用缓存

缓存的操作流程一般是这样的：

![](/assets/images/posts/cache/cache-1.png)

1. 读取缓存中是否有相关数据
2. 如果缓存中有相关数据，直接返回（缓存命中“hit”）
3. 如果缓存中没有相关数据，则从数据库读取相关数据（缓存未命中“miss”），再将数据放入缓存，然后返回。

伪代码：

```
Object value = cache.get(key);
if (value != null) {
	return value;
}
value = db.get(key);
if (value != null) {
	cache.put(key, value)
}
return value;
```

缓存的命中率 = 命中缓存请求个数/总缓存访问请求个数 = hit/(hit+miss)

对于一般的应用的话db的读写频率的比例大约在10:1左右，读的次数明显大于写的次数，大多数请求到了缓存这里就给搞定了，只有少量的穿透来维护数据的更新.这种做法是明智的，服务器读内存的速度比读硬盘的速度快 10^5-10^6倍，使用缓存可以大大增加用户的响应速度和服务器的处理能力。

然而上述的代码却存在一些比较公共的缓存问题

# 缓存面临的问题

## 缓存并发

一个缓存如果失效，可能出现多个进程同时查询DB，同时设置缓存的情况，如果并发确实很大，这也可能造成DB压力过大，还有缓存频繁更新的问题。

解决思路：

对缓存查询加锁，如果KEY不存在，就加锁，然后查DB入缓存，然后解锁；其他进程如果发现有锁就等待，然后等解锁后返回数据或者进入DB查询。但这样会降低系统的吞吐量，需要根据实际情况考虑是否这么做。

**因为字符串也是共享的，我们直接锁缓存key，会阻塞其他使用这个字符串的操作行为，所以我们要加锁的字符串要是一个基于KEY生成的特殊对象.**

```
Object value = cache.get(key);
if (value != null) {
	return value;
}
String lockKey = key + "1190000005886009";
synchronized (lockKey) {
	value = cache.get(key);
	if (value != null) {
		return value;
	}
	value = db.get(key);
	if (value != null) {
		cache.put(key, value)
	}
	return value;
}
```

**在获取到锁之后，我们需要再次从缓存中读取数据，如果有相关数据之间返回**

## 缓存穿透

缓存穿透是指用户查询的数据在数据库一定没有，自然在缓存中也不会有。这样就导致用户查询的时候，每次都要去数据库中查询。在流量大时，可能数据库就挂掉了。

在主从架构，读写分离中，如果写到主库却未同步到从库，就会出现请求穿透到数据库的情况

解决思路：

**1. 存放空值**

如果查询数据库也为空，直接设置一个默认值存放到缓存，这样第二次到缓冲中获取就有值了，而不会继续访问数据库，这种办法最简单粗暴。

比如我们这个不存在的key预先设定一个特定值"NOT_EXISTS"。在缓存返回这个NOT_EXISTS值的时候，我们的应用就可以认为这是不存在的key，那调用方就可以决定是等待一段事件后重试，还是直接返回不存在。

当然在该KEY对应的数据被插入之后，应该清理缓存，或者将不存在KEY的缓存时间稍微设置短一点。

```
Object value = cache.get(key);
if (value != null) {
	return value;
}
String lockKey = key + "1190000005886009";
synchronized (lockKey) {
	value = cache.get(key);
	if (value != null) {
		return value;
	}
	value = db.get(key);
	if (value == null) {
		value = "NOT_EXISTS"
	}
	cache.put(key, value)
	return value;
}
```

**2.布隆过滤器**

采用布隆过滤器，将所有可能存在的数据哈希到一个足够大的BitSet中，不存在的数据将会被拦截掉，从而避免了对底层存储系统的查询压力。关于布隆过滤器可以在网上搜索相关介绍，它的原理就是利用多个HASH算法将一个对象映射成一个bit数组(也称为bitmap)里面的多个点。以后判断就只要HASH后和数组里面的值亦或下就好了，效率很高。

![](/assets/images/posts/cache/cache-2.png)

> BloomFilter的介绍https://edgar615.github.io/bloom-filter.html

针对于一些恶意攻击，攻击带过来的大量key 是不存在的，那么我们采用第一种方案就会缓存大量不存在key的数据，过多的占用缓存空间。此时我们采用第一种方案就不合适了，我们完全可以先对使用第二种方案进行过滤掉这些key。

针对这种key异常多、请求重复率比较低的数据，我们就没有必要进行缓存，使用第二种方案直接过滤掉。而对于空数据的key有限的，重复率比较高的，我们则可以采用第一种方式进行缓存。


当缓存空间满了，同步失败，网络阻塞，缓存写失败等原因，会出现缓存服务器上并没有这个key。或者因为同步中断，在主从架构中，写到主却未同步到从的悲剧，就会出现请求穿透到DB层的情况。

当发生大量的缓存穿透，例如对某个失效的缓存的大并发访问就造成了缓存雪崩。

## 缓存雪崩

缓存雪崩是由于在缓存失效(缓存服务器重启或者大量缓存集中在某一个时间段失效)，新缓存还未到的中间时间内，所有请求都会去查询数据库，而对数据库造成巨大压力甚至宕机。

解决思路：

1. 在缓存失效后，通过加锁或者队列来控制读数据库写缓存的线程数量。比如对某个key只允许一个线程查询数据和写缓存，其他线程等待。这种办法虽然能缓解数据库的压力，但是同时又降低了系统的吞吐量。和缓存并发是同一种处理方式。
2. 不同的key，设置不同的过期时间，让缓存失效的时间点尽量均匀。避免缓存雪崩的出现。
3. 二级缓存，A1为原始缓存，A2为拷贝缓存，A1缓存失效时间设置为短期，A2设置为长期，当A1失效的时候，利用同步（或者其他手段）让一个线程去查询并更新缓存，其他线程直接返回C2的数据。
4. 使用分布式缓存。设计合理的缓存分布算法，让缓存均匀地分布到各个节点，这样一台缓存服务器挂了只是有部分缓存丢失，不会所有压力集中到数据库

## 加锁排队的优化
加锁排队只是为了减轻数据库的压力，并没有提高系统吞吐量。假设在高并发下，缓存重建期间key是锁着的，这是过来1000个请求999个都在阻塞的，同样会导致用户等待超时。对于这个问题对应的解决思路是：

**给每一个缓存数据增加相应的缓存标记，记录缓存的是否失效，如果缓存标记失效，则更新数据缓存。**

```
Object value = cache.get(key);
//获取标记值
String cacheSign = key + "_Sign";
Object sign = cache.get(cacheSign)
if (sign == null) {
	//过期，用一个线程在后台更新缓存
	new Runnable() {
		Object v = db.get(key);
		cache.put(key, v, cacheTime * 2);
		cache.put(cacheSign, cacheSign, cacheTime);
	}.start()
}
return value;//会出现脏数据
```

- 缓存标记：记录缓存数据是否过期，如果过期会触发通知另外的线程在后台去更新实际key的缓存。
- 缓存数据：它的过期时间比缓存标记的时间延长1倍，例：标记缓存时间30分钟，数据缓存设置为60分钟。 这样，当缓存标记key过期后，实际缓存还能把旧数据返回给调用端，直到另外的线程在后台更新完成后，才会返回新缓存。

# 缓存预热

缓存预热就是系统上线后，将相关的缓存数据直接加载到缓存系统。这样避免在用户请求的时候，再去加载相关的数据。

在单机系统情况下比较简单：

1. 直接写个缓存刷新页面，上线时手工操作下
2. 数据量不大，可以在WEB系统启动的时候加载
3. 搞个定时器定时刷新缓存，或者由用户触发都行

分布式缓存系统，如Memcached，Redis，比如缓存系统比较大，由十几台甚至几十台机器组成，这样预热会复杂一些：

解决思路：

1. 写个程序去跑
2. 单个缓存预热框架

# 缓存降级

当访问量剧增、服务出现问题（如响应时间慢或不响应）或非核心服务影响到核心流程的性能时，仍然需要保证服务还是可用的，即使是有损服务。系统可以根据一些关键数据进行自动降级，也可以配置开关实现人工降级。

降级的最终目的是保证核心服务可用，即使是有损的。而且有些服务是无法降级的（如加入购物车、结算）。

在进行降级之前要对系统进行梳理，看看系统是不是可以丢卒保帅；从而梳理出哪些必须誓死保护，哪些可降级；比如可以参考日志级别设置预案：

- 一般：比如有些服务偶尔因为网络抖动或者服务正在上线而超时，可以自动降级；
- 警告：有些服务在一段时间内成功率有波动（如在95~100%之间），可以自动降级或人工降级，并发送告警；
- 错误：比如可用率低于90%，或者数据库连接池被打爆了，或者访问量突然猛增到系统能承受的最大阀值，此时可以根据情况自动降级或者人工降级；
- 严重错误：比如因为特殊原因数据错误了，此时需要紧急人工降级。

# 参考资料

http://www.pianshen.com/article/4878312465/

https://tech.meituan.com/2017/03/17/cache-about.html

https://community.qingcloud.com/topic/463

https://mp.weixin.qq.com/s/JCFx-GNjueLLOEjWMKbLRQ
