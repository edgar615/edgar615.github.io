---
layout: post
title: Linux内存
date: 2019-09-05
categories:
    - linux
comments: true
permalink: linux-memory.html
---

# 1. 内存

内存是计算机的主存储器。内存为进程开辟出进程空间，让进程在其中保存数据。简单地说，内存就是一个数据货架。内存有一个最小的存储单位，大多数都是一个字节。内存用**内存地址（memory  address）**来为每个字节的数据顺序编号。因此，内存地址说明了数据在内存中的位置。内存地址从0开始，每次增加1。这种线性增加的存储器地址称为**线性地址（linear  address）**。为了方便，我们用十六进制数来表示内存地址，比如0x00000003、0x1A010CB0。这里的“0x”用来表示十六进制。“0x”后面跟着的，就是作为内存地址的十六进制数。

内存地址的编号有上限。**地址空间的范围和地址总线（address  bus）的位数直接相关**。CPU通过地址总线来向内存说明想要存取数据的地址。以英特尔32位的80386型CPU为例，这款CPU有32个针脚可以传输地址信息。每个针脚对应了一位。如果针脚上是高电压，那么这一位是1。如果是低电压，那么这一位是0。32位的电压高低信息通过地址总线传到内存的32个针脚，内存就能把电压高低信息转换成32位的二进制数，从而知道CPU想要的是哪个位置的数据。用十六进制表示，32位地址空间就是从0x00000000 到0xFFFFFFFF。

内存的存储单元采用了**随机读取存储器（RAM， Random Access  Memory）**。所谓的“随机读取”，是指存储器的读取时间和数据所在位置无关。与之相对，很多存储器的读取时间和数据所在位置有关。就拿磁带来说，我们想听其中的一首歌，必须转动带子。如果那首歌是第一首，那么立即就可以播放。如果那首歌恰巧是最后一首，我们快进到可以播放的位置就需要花很长时间。我们已经知道，进程需要调用内存中不同位置的数据。如果数据读取时间和位置相关的话，计算机就很难把控进程的运行时间。因此，**随机读取的特性是内存成为主存储器的关键因素。**

内存提供的存储空间，除了能满足内核的运行需求，还通常能支持运行中的进程。即使进程所需空间超过内存空间，内存空间也可以通过少量拓展来弥补。换句话说，内存的存储能力，和计算机运行状态的数据总量相当。内存的缺点是不能持久地保存数据。一旦断电，内存中的数据就会消失。因此，计算机即使有了内存这样一个主存储器，还是需要硬盘这样的外部存储器来提供持久的储存空间。

# 2. 虚拟内存

内存的一项主要任务，就是存储进程的相关数据。有趣的是，尽管进程和内存的关系如此紧密，但**进程并不能直接访问内存**。在Linux下，进程不能直接读写内存中地址为0x1位置的数据。**进程中能访问的地址，只能是虚拟内存地址（virtual memory address**）。操作系统会把虚拟内存地址翻译成真实的内存地址。这种内存管理方式，称为**虚拟内存（virtual memory）**。

每个进程都有自己的一套虚拟内存地址，用来给自己的进程空间编号。进程空间的数据同样以字节为单位，依次增加。从功能上说，虚拟内存地址和物理内存地址类似，都是为数据提供位置索引。进程的虚拟内存地址相互独立。因此，两个进程空间可以有相同的虚拟内存地址，如0x10001000。虚拟内存地址和物理内存地址又有一定的对应关系，如图1所示。对进程某个虚拟内存地址的操作，会被CPU翻译成对某个具体内存地址的操作。

![](/assets/images/posts/linux-memory/linux-memory-1.png)

应用程序来说对物理内存地址一无所知。它只可能通过虚拟内存地址来进行数据读写。**程序中表达的内存地址，也都是虚拟内存地址**。进程对虚拟内存地址的操作，会被操作系统翻译成对某个物理内存地址的操作。由于翻译的过程由操作系统全权负责，所以应用程序可以在全过程中对物理内存地址一无所知。

本质上说，虚拟内存地址剥夺了应用程序自由访问物理内存地址的权利。进程对物理内存的访问，必须经过操作系统的审查。因此，掌握着内存对应关系的操作系统，也掌握了应用程序访问内存的闸门。**借助虚拟内存地址，操作系统可以保障进程空间的独立性。**只要操作系统把两个进程的进程空间对应到不同的内存区域，就让两个进程空间成为“老死不相往来”的两个小王国。两个进程就不可能相互篡改对方的数据，进程出错的可能性就大为减少。

另一方面，有了虚拟内存地址，**内存共享**也变得简单。**操作系统可以把同一物理内存区域对应到多个进程空间**。这样，不需要任何的数据复制，多个进程就可以看到相同的数据。内核和共享库的映射，就是通过这种方式进行的。每个进程空间中，最初一部分的虚拟内存地址，都对应到物理内存中预留给内核的空间。这样，所有的进程就可以共享同一套内核数据。共享库的情况也是类似。对于任何一个共享库，计算机只需要往物理内存中加载一次，就可以通过操纵对应关系，来让多个进程共同使用。

简单总结一下，**虚拟内存是操作系统物理内存和进程之间的中间层**，它为进程隐藏了物理内存这一概念，为进程提供了更加简洁和易用的接口以及更加复杂的功能。

# 3. **内存分页**

虚拟内存地址和物理内存地址的分离，给进程带来便利性和安全性。但虚拟内存地址和物理内存地址的翻译，又会额外耗费计算机资源。在多任务的现代计算机中，虚拟内存地址已经成为必备的设计。那么，**操作系统必须要考虑清楚，如何能高效地翻译虚拟内存地址。**

记录对应关系最简单的办法，就是把对应关系记录在一张表中。为了让翻译速度足够地快，**这个表必须加载在内存中**。不过，这种记录方式惊人地浪费。如果树莓派1GB物理内存的每个字节都有一个对应记录的话，那么光是对应关系就要远远超过内存的空间。由于对应关系的条目众多，搜索到一个对应关系所需的时间也很长。这样的话，会让操作系统陷入瘫痪。

因此，Linux采用了分页（paging）的方式来记录对应关系。所谓的分页，就是以更大尺寸的单位页（page）来管理内存。在Linux中，通常每页大小为4KB。如果想要获取当前的内存页大小，可以使用命令：

```
# getconf PAGE_SIZE
4096
```

返回的4096代表每个内存页可以存放4096个字节，即4KB。Linux把物理内存和进程空间都分割成页。

内存分页，可以极大地减少所要记录的内存对应关系。我们已经看到，以字节为单位的对应记录实在太多。如果把物理内存和进程空间的地址都分成页，内核只需要记录页的对应关系，相关的工作量就会大为减少。由于每页的大小是每个字节的4000倍。因此，内存中的总页数只是总字节数的四千分之一。对应关系也缩减为原始策略的四千分之一。分页让虚拟内存地址的设计有了实现的可能。

**无论是虚拟页，还是物理页，一页之内的地址都是连续的**。这样的话，一个虚拟页和一个物理页对应起来，页内的数据就可以按顺序一一对应。这意味着，虚拟内存地址和物理内存地址的末尾部分应该完全相同。大多数情况下，每一页有4096个字节。由于4096是2的12次方，所以地址最后12位的对应关系天然成立。我们把地址的这一部分称为**偏移量（offset）**。偏移量实际上表达了该字节在页内的位置。地址的前一部分则是**页编号**。操作系统只需要记录页编号的对应关系。

![](/assets/images/posts/linux-memory/linux-memory-2.png)

换算过程分为以下 3 个步骤：这个换算的过程：如果页大小是 4K，假设程序要访问地址：100,000。那么计算过程如下。

1. 通过虚拟地址计算页编号；

2. 根据页编号查找对应的物理页编号

3. 根据偏移量找到对应的物理地址

# 4. **页表**

内存分页制度的关键，在于管理进程空间页和物理页的对应关系。操作系统把对应关系记录在**分页表（page  table）**中。这种对应关系让上层的抽象内存和下层的物理内存分离，从而让Linux能灵活地进行内存管理。**由于每个进程会有一套虚拟内存地址，那么每个进程都会有一个分页表。**为了保证查询速度，**分页表也会保存在内存中**。分页表有很多种实现方式，最简单的一种分页表就是把所有的对应关系记录到同一个线性列表中，即上图中的“对应关系”部分所示。

页表实际上存储在 CPU 的内存管理单元 **MMU** 中，这样，正常情况下，处理器就可以直接通过硬件，找出要访问的内存。

![](/assets/images/posts/linux-memory/linux-memory-3.png)

当 CPU 需要执行一条指令时，如果指令中涉及内存读写操作，CPU 会把虚拟地址给 MMU，MMU 自动完成虚拟地址到真实地址的计算；然后，MMU 连接了地址总线，帮助 CPU 操作真实地址。

这样的设计，就不需要在编写应用程序的时候担心虚拟地址到物理地址映射的问题。我们把全部难题都丢给了操作系统——操作系统要确定MMU 可以读懂自己的页表格式。

在 32 位的环境下，虚拟地址空间共有 4GB，假设一个页的大小是 4KB（2^12），那么就需要大约 100 万 （2^20） 个页，每个页表需要 4 个字节大小来存储，那么整个 4GB 空间的映射就需要有 `4MB` 的内存来存储页表。

这 4MB 大小的页表，看起来也不是很大。但是因为每个进程都是有自己的虚拟地址空间的，也就说都有自己的页表。那么，`100` 个进程的话，就需要 `400MB` 的内存来存储页表，这是非常大的内存了，更别说 64 位的环境了。

另外这种单一的连续分页表，需要给每一个虚拟页预留一条记录的位置。但对于任何一个应用进程，其进程空间真正用到的地址都相当有限。我们还记得，进程空间会有栈和堆。进程空间为栈和堆的增长预留了地址，但栈和堆很少会占满进程空间。这意味着，如果使用连续分页表，很多条目都没有真正用到。因此，Linux中的分页表，采用了多层的数据结构。**多层的分页**表能够减少所需的空间。

我们来看一个简化的分页设计，用以说明Linux的多层分页表。我们把地址分为了页编号和偏移量两部分，用单层的分页表记录页编号部分的对应关系。对于多层分页表来说，会进一步分割页编号为两个或更多的部分，然后用两层或更多层的分页表来记录其对应关系，

![](/assets/images/posts/linux-memory/linux-memory-4.png)

在上面的例子中，页编号分成了两级。第一级对应了前8位页编号，用2个十六进制数字表示。第二级对应了后12位页编号，用3个十六进制编号。二级表记录有对应的物理页，即保存了真正的分页记录。二级表有很多张，每个二级表分页记录对应的虚拟地址前8位都相同。比如二级表0x00，里面记录的前8位都是0x00。翻译地址的过程要跨越两级。我们先取地址的前8位，在一级表中找到对应记录。该记录会告诉我们，目标二级表在内存中的位置。我们再在二级表中，通过虚拟地址的后12位，找到分页记录，从而最终找到物理地址。

多层分页表就好像把完整的电话号码分成区号。我们把同一地区的电话号码以及对应的人名记录同通一个小本子上。再用一个上级本子记录区号和各个小本子的对应关系。如果某个区号没有使用，那么我们只需要在上级本子上把该区号标记为空。同样，一级分页表中0x01记录为空，说明了以0x01开头的虚拟地址段没有使用，相应的二级表就不需要存在。正是通过这一手段，**多层分页表占据的空间要比单层分页表少了很多**。做个简单的计算，假设只有 20% 的一级页表项被用到了，那么页表占用的内存空间就只有 4KB（一级页表） + 20% * 4MB（二级页表）= `0.804MB`，这对比单级页表的 `4MB` 是不是一个巨大的节约？

多层分页表还有另一个优势。**单层分页表必须存在于连续的内存空间。而多层分页表的二级表，可以散步于内存的不同位置。这样的话，操作系统就可以利用零碎空间来存储分页表**。还需要注意的是，这里简化了多层分页表的很多细节。

为了存储 64 位操作系统中虚拟内存的映射数据，Linux 在 2.6.10 中引入了四层的页表辅助虚拟地址的转换，在 4.11 中引入了五层的页表结构，在未来还可能会引入更多层的页表结构以支持 64 位的虚拟地址

![](/assets/images/posts/linux-memory/linux-memory-5.png)

# 5.  TLB

虽然只需要4k的初始页目录就可以支持起一个256T的进程地址空间。但是，这也带来了额外的问题，页表是存在内存里的。那就是一次内存IO光是虚拟地址到物理地址的转换就要去内存查4次页表，再算上真正的内存访问，竟然需要5次内存IO才能获取一个内存数据!

和CPU的L1、L2、L3的缓存思想一致，既然进行地址转换需要的内存IO次数多，且耗时。那么干脆就在CPU里把页表尽可能地cache起来不就行了么，所以就有了**TLB(Translation Lookaside Buffer)**，专门**用于改进虚拟地址到物理地址转换速度的缓存**。其访问速度非常快，和寄存器相当，比L1访问还快。

![](/assets/images/posts/linux-memory/linux-memory-6.png)

有了TLB之后，CPU访问某个虚拟内存地址的过程如下

1. CPU产生一个虚拟地址
2. MMU从TLB中获取页表，翻译成物理地址
3. MMU把物理地址发送给L1/L2/L3/内存
4. L1/L2/L3/内存将地址对应数据返回给CPU

由于第2步是类似于寄存器的访问速度，所以如果TLB能命中，则虚拟地址到物理地址的时间开销几乎可以忽略。

TLB 的作用就是根据输入的 Page Number，找到 Frame Number。TLB 是硬件实现的，因此速度很快。因为用户的局部程序，往往会反复利用相同的内存地址。比如说 for 循环会反复利用循环变量，因此哪怕是只有几十个缓存行的 TLB，也会有非常高的命中率。而且现在的多核 CPU，会为每个核心提供单独的 TLB。这样，相当于减少了 TLB 的冲突。比如酷睿 i7 CPU 当中，每个核心都有自己的 TLB，而且 TLB 还进行了类似 CPU 缓存的分级策略。在 i7 CPU 中，L1 级 TLB 一共 64 个，L2 级 TLB 一共 1024 个。通过这样的设计，绝大多数的页表查询就可以用 TLB 实现了

## 5.1. **TLB 失效（Miss）**

因为TLB并不是很大，只有4k，而且现在逻辑核又造成会有两个进程来共享。所以可能会有**cache miss**的情况出现。而且一旦TLB miss造成的后果可比物理地址cache miss后果要严重一些，最多可能需要进行5次内存IO才行。这种情况，又分成两种

**一种是软失效（Soft Miss）**，这种情况 Frame还在内存中，只不过 TLB 缓存中没有。那么这个时候需要刷新 TLB 缓存。如果 TLB 缓存已经满了，就需要选择一个已经存在的缓存条目进行覆盖。具体选择哪个条目进行覆盖，我们称为缓存置换（缓存不够用了，需要置换）。缓存置换时，通常希望高频使用的数据保留，低频使用的数据被替换。比如常用的 LRU（Least Recently Used）算法就是基于这种考虑，**每次置换最早使用的条目**。

**另一种情况是硬失效（Hard Miss)**，这种情况下对应的 Frame 没有在内存中，需要从磁盘加载。这种情况非常麻烦，首先操作系统要触发一个**缺页中断**（原有需要读取内存的线程被休眠），然后中断响应程序开始从磁盘读取对应的 Frame 到内存中，读取完成后，再次触发中断通知更新 TLB，并且唤醒被休眠的线程去排队。注意，线程不可能从休眠态不排队就进入执行态，因此 Hard Miss 是相对耗时的。

**无论是软失效、还是硬失效，都会带来性能损失，这是我们不希望看到的。因此缓存的设计，就非常重要了。**

失效产生的原因

- **非法操作访问越界**
  这种情况产生的影响也是最大的，也是Coredump的重要来源，比如空指针解引用或者权限问题等都会出现缺页错误。
- **使用malloc新申请内存**
  malloc机制是延时分配内存，当使用malloc申请内存时并未真实分配物理内存，等到真正开始使用malloc申请的物理内存时发现没有才会启动申请，期间就会出现Page Fault。
- **访问数据被swap换出**
  物理内存是有限资源，当运行很多进程时并不是每个进程都活跃，对此OS会启动内存页面置换将长时间未使用的物理内存页帧放到swap分区来腾空资源给其他进程，当存在于swap分区的页面被访问时就会触发Page Fault从而再置换回物理内存。

## 6. 大内存分页

在 Linux 操作系统上运行内存需求量较大的应用程序时，由于其采用的默认页面大小为 4KB，因而将会产生较多 TLB Miss 和缺页中断，从而大大影响应用程序的性能。当操作系统以 2MB 甚至更大作为分页的单位时，将会大大减少 TLB Miss 和缺页中断的数量，显著提高应用程序的性能。

假设应用程序需要 2MB 的内存，如果操作系统以 4KB 作为分页的单位，则需要 512 个页面，进而在 TLB 中需要 512 个表项，同时也需要 512 个页表项，操作系统需要经历至少 512 次 TLB Miss 和 512 次缺页中断才能将 2MB 应用程序空间全部映射到物理内存；然而，当操作系统采用 2MB 作为分页的基本单位时，只需要一次 TLB Miss 和一次缺页中断，就可以为 2MB 的应用程序空间建立虚实映射，并在运行过程中无需再经历 TLB Miss 和缺页中断（假设未发生 TLB 项替换和 Swap）。

```
# 查看HugePages大小
# grep Huge /proc/meminfo
AnonHugePages:         0 kB
ShmemHugePages:        0 kB
FileHugePages:         0 kB
HugePages_Total:       0
HugePages_Free:        0
HugePages_Rsvd:        0
HugePages_Surp:        0
Hugepagesize:       2048 kB
Hugetlb:               0 kB
```

# 7.  Swapping 机制

 Swapping 机制是操作系统将物理内存页中的内容拷贝到硬盘上交换空间（Swap Space）以释放内存的过程，物理内存和硬盘上的交换分区组成了操作系统上可用的虚拟内存，而这些交换空间都是系统管理员预先配置好的

![](/assets/images/posts/linux-memory/linux-memory-7.png)

正是因为 Linux 上的所有进程都会通过虚拟内存这一层抽象间接与物理内存打交道，而 Swapping  也充分利用了该特性，它能够让应用程序看到操作系统内存充足的假象，然而并不知道它使用的部分虚拟内存其实在磁盘上，因为内存和磁盘的读写速度上的巨大差异，这部分虚拟内存的读写非常缓慢。如此巨大的性能差异使得触发 Swapping 的进程可能会遇到性能损失，同一个页面的频繁换入换出会导致极其明显的性能抖动。

Swapping包括换出和换入两个过程。

- 换出，就是把进程暂时不用的内存数据存储到磁盘中，并释放这些数据占用的内存。
- 换入，则是在进程再次访问这些内存的时候，把它们从磁盘读到内存中来。

Linux 提供了两种不同的方法启用 Swapping，分别是 Swap 分区（Swap Partition）和 Swap 文件（Swapfile）：

- Swap 分区是硬盘上的独立区域，该区域只会用于交换分区，其他的文件不能存储在该区域上，我们可以使用 `swapon -s` 命令查看当前系统上的交换分区；
- Swap 文件是文件系统中的特殊文件，它与文件系统中的其他文件也没有太多的区别；

Swap  分区的大小是需要系统管理员手动设定的，然而不同的场景最好设置不同交换分区大小，例如：桌面系统的交换分区大小可以是系统内存的两倍，这可以让我们同时运行更多的应用程序；服务器的交换分区应该关闭或者使用少量的交换分区，不过一旦启用交换分区，就应该引入监控监控应用程序的性能。

我们到现在已经对 Linux 上的 Swapping 有了一定的了解，接下来回到这篇文章想要讨论的问题 — 『为什么 Linux 需要 Swapping』，我们将从以下两个方面介绍 Swapping 解决的问题、触发入口和执行路径：

- Swapping 可以直接将进程中使用相对较少的页面换出内存，立刻给正在执行的进程分配内存；
- Swapping 可以将进程中的闲置页面换出内存，为其他进程未来使用内存做好准备；

**内存不足**

当系统需要的内存超过了可用的物理内存时，内核会将内存中不常使用的内存页交换到磁盘上为当前进程让出内存，保证正在执行的进程的可用性，这个内存回收的过程是强制的直接内存回收（Direct Page Reclaim）。

![](/assets/images/posts/linux-memory/linux-memory-8.png)

**内存闲置**

应用程序在启动阶段使用的大量内存在启动后往往都不会使用，通过后台运行的守护进程，我们可以将这部分只使用一次的内存交换到磁盘上为其他内存的申请预留空间。kswapd 是 Linux 负责页面置换（Page  replacement）的守护进程，它也是负责交换闲置内存的主要进程，它会在空闲内存低于一定水位时，回收内存页中的空闲内存保证系统中的其他进程可以尽快获得申请的内存，如下图所示：

![](/assets/images/posts/linux-memory/linux-memory-9.png)

当空闲页面小于 `WMARK_LOW` 时，kswapd 进程才会开始工作，它会将内存页交换到磁盘上直到空闲页面的水位回到 `WMARK_HIGH`，不过当空闲页面的水位低于 `WMARK_MIN` 时会触发上一节提到的内存直接回收，而水位高于 `WMARK_HIGH` 则意味着空闲内存充足，不需要进行回收。

# 8. 参考资料

www.cnblogs.com/vamei/p/9329278.html

https://mp.weixin.qq.com/s/HJB_ATQFNqG82YBCRr97CA

https://mp.weixin.qq.com/s/mssTS3NN7-w2df1vhYSuYw