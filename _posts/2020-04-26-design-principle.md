---
layout: post
title: 一些架构原则
date: 2020-04-26
categories:
    - 设计
comments: true
permalink: design-principle.html
---

**基本原则**

**原则1：** KISS (Keep it simple,sutpid) 和保持每件事情都尽可能的简单，用最简单的解决方案来解决问题。但是如果不知道什么是复杂，怎么知道如何保持简单？很多团队声称的 KISS，不过是偷懒的借口。如果项目不死，总有一天团队需要为前面的潦草、Simple 和 Stupid 埋单。

**原则2：**YAGNI（你不需要它）原则 ，只在需要时构建。

**原则3：**先保证能够正常运行，然后优化它使其更好，最后逐渐让它变得完美。使用迭代开发，采用敏捷开发模式。为每个功能制定一个开发周期（最多2周），然后不断迭代。

**原则4：**自动化测试是构建稳定、高质量产品的唯一方法。通过自动化测试提升创造力，所有一切都可以自动化！在设计时应当好好考虑自动化。

**原则5：**功能的设计和测试尽可能独立。如果在设计时考虑到这一点，长远来看，它将省去很多麻烦，否则只有一切构建完成时你才可以开始测试整个系统。此外，遵循这个原则，版本发布也会更加顺利。

高流量问题带来的一些相关的问题。

- **雪崩效应**——如果用户看到“服务开小差”，他的第一反应一定是再刷一次；如果是微服务架构，服务与服务之间可能会有自动重试机制。而这些，会让已经半死的系统死的更透彻。对此类问题，一般使用断路器的方案，简单来说就是，如果一个服务已经证明快挂了，就别再调用了，直接fallback。等一会再试。nginx里的upstream控制有max_fails和fail_timeout处理这个问题。Hystrix也实现了该机制。但断路了不等于让用户看到404页面骂娘，一定要结合业务+产品设计来实现断路方案。
- **无效的服务响应**——在高压下，可以简单将等待处理的服务看作是在排队，队首的请求被处理。但被最终“见”到处理逻辑的请求从队尾排到队首时可能已经过了比较长的时间，而客户端那边可能早就超时了。所以业务服务处理了也是白处理。这时如果队列系统做得好，**比如要处理前先猜一次是不是处理完了会超时，如果是就忽略扔掉。可以减少这种问题的发生几率**。这也算是一种服务降级。
- **大量的TIME_WAIT**——如果业务服务器的压力造成服务端大量主动关闭连接，就会产生大量的TIME_WAIT状态的TCP链接。这些链接会在数分钟内像僵尸一样堆在那里，榨干所有的连接数。这种问题尤其以自研业务服务框架容易出现。
- **一致性**——为了服务降级，可能会把用户请求放内存里缓一缓，再批量进DB。那么一旦系统出现故障，就意味着比如下单数据不一致，支付状态不一致等问题。有时，这些问题在业务上极大的影响用户的使用体验。当系统降级时，尽量保证，要不就告诉用户现在不能给你服务，要服务了结果就明确。对于交易这种业务，事前打脸还是比事后扯皮要好一些。两害取其轻。
- **系统可能会临时stop the world**——对于java这样的系统，会因为GC而暂时卡那么一下；对于mongoDB，可能因为要底层flush数据到磁盘，也会卡那么一下；平时写的什么正则表达式处理一类的逻辑，在高峰期也可能会卡那么一下……  平时一般没事，但是赶上高峰时，这些问题一旦出现就有可能成为压垮骆驼的最后一根稻草。因此平时还是多多压测和演习，心里踏实。

**预先准备**

当设计一个业务时，产品设计和研发团队应该找个时间，除了讨论产品本身怎么实现之外，还应该关心一下如下几点的实施：

**流量估算**。到底大概有多少人可能会用呢？对于大公司，都有长时间运营的经验，可以参照之前的产品/活动给出一个量化的估算结果。

但是小公司往往就只能拍脑袋。但即便是拍脑袋也比没有强，可以作为设计容量的依据。这下你明白为啥有些公司面试时会出“你觉得本城市有多少个辆汽车”这样的题目了吧。

作为一个经验，可以把**设计流量*3作为系统压力的下限**——即，实现完了要压测，压测得到的结果要达到设计流量 * 3。当然如果是你的话，要 * 4， * 5都可以，关键是要给系统留些缓冲。

一旦发生了什么，不至于挂的太惨。此时，一般会得到一个带缓存的业务服务系统。考虑到缓存高于后台服务2～3个数量级的性能优势，多撑几倍流量一般不成问题。

**降级方案**。降级总得是用户可以买账的方式才行，不能瞎降。能降级成什么样，显示成什么样子，都得预先设计好。

UI上有的要配图，有的要出警告语提示。而作为后台服务器，需要有对应的实时开关，一旦设置，立刻进入降级方案。

但是，如果核心服务就是热点本身，就没得降级，那就尴尬了…… 比如下单就是下单，不能下一半，不能砍掉支付，不能随机性有的能买有的不能买。这时就得靠限流。

**限流方案**。上面提到了种种限流算法——计数器、滑动窗口、滴漏、服务token、请求队列化，等办法技术在更加传统的模版式页面的网站更容易做——整个界面是由一个GET请求在后台通过模版产生的。所以只要在这个请求处理过程中做限流控制即可。

但是在SPA或者移动端App时，一个界面可能是由数个或者数十个Ajax接口分批获得。每个请求都做限流可能会得到随机的半残的界面——有几个接口没限制，有几个被限制了。

此时做限流还得考虑前后端架构设计。一般来讲，每个主要界面都应该有个主控接口来实现限流（比如产品详情接口）——即，一旦该接口说限流了，后续的前端代码就得配合按照预先的设计显示限流后的界面。

同时会影响关键资源的接口在后端要再做一道限流——毕竟你不知道有没有人绕开前端直接压接口使坏不是。嗯，抢票就是这么来的。

**提前安排开发和演练排期**。如果一切安排妥当，就可以做作演习了。你可以找个没人用你服务的时间点（大半夜？）使用流量replay压一下你的真实生产环境，看看真的发生了流量增高的问题，系统是否足够健壮能够应对，之前设计的种种方案是不是可以达到设计的需要。

根据**墨菲定律**，可能会发生的事情一定会发生，不经演练的系统上线到了出问题的时候100%会让你大开眼界。

然而，高能预警，做演练时：**千万千万不要产生像你的模拟流量代替用户下了一单并且扣款的事情……**