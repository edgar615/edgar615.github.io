---
layout: post
title: 负载均衡
date: 2020-04-15
categories:
    - 分布式
comments: true
permalink: loadbalance.html
---

从单机网站到分布式网站，很重要的区别是业务拆分和分布式部署，将应用拆分后，部署到不同的机器上，实现大规模分布式系统。分布式和业务拆分解决了，从集中到分布的问题，但是每个部署的独立业务还存在单点的问题和访问统一入口问题，为解决单点故障，我们可以采取冗余的方式。将相同的应用部署到多台机器上。解决访问统一入口问题，我们可以在集群前面增加负载均衡设备，实现流量分发。

负载均衡（Load Balance），意思是将负载（工作任务，访问请求）进行平衡、分摊到多个操作单元（服务器，组件）上进行执行。是解决高性能，单点故障（高可用），扩展性（水平伸缩）的终极解决方案。

# 原理
系统的扩展可分为纵向（垂直）扩展和横向（水平）扩展。纵向扩展，是从单机的角度通过增加硬件处理能力，比如CPU处理能力，内存容量，磁盘等方面，实现服务器处理能力的提升，不能满足大型分布式系统（网站），大流量，高并发，海量数据的问题。因此需要采用横向扩展的方式，通过添加机器来满足大型网站服务的处理能力。比如：一台机器不能满足，则增加两台或者多台机器，共同承担访问压力。这就是典型的集群和负载均衡架构：如下图：

```
						          +-------------+ 
			+-------------+ ------>   |     应用A   |
			|             |           +-------------+ 
	------>	| 负载均衡器  |
			|             |  		  +-------------+ 
			+-------------+	------>   |     应用B   |
									  +-------------+ 
```

负载均衡的作用：

1. 解决并发压力，提高应用处理性能（增加吞吐量，加强网络处理能力）；
2. 提供故障转移，实现高可用；
3. 通过添加或减少服务器数量，提供网站伸缩性（扩展性）；
4. 安全防护；（负载均衡设备上做一些过滤，黑白名单等处理）

# 负载均衡的分类

谈到负载均衡，大家都会想到 Nginx，通常我们会用它做应用服务的负载均衡。

一般它的并发量在 5W 左右，如果并发量再高就需要做 Nginx 的集群了。但 Nginx 之上还有一层负载均衡器，是它把网络请求转发给 Nginx 的，同时还会肩负网络链路，防火墙等工作。

它就是“硬件负载均衡器”，一般安装在外部网络与内网服务器之间。比较流行的有 NetScaler，F5，Radware，Array 等产品。

![](/assets/images/posts/loadbalance/loadbalance-1.png)

相对于“硬件负载均衡器”来说，对内网服务器进行负载均衡就属于“软件负载均衡器”。例如：LVS，HAProxy，Nginx。

**硬件负载均衡工作在“接入层”，**主要任务是多链路负载均衡，防火墙负载均衡，服务器负载均衡。

**软件负载均衡工作在“代理层”，**主要任务是反向代理，缓存，数据验证等等。

![](/assets/images/posts/loadbalance/loadbalance-2.png)

硬件负载均衡在接入层获得网络请求，然后转交给软件负载均衡，用同样的方式处理返回的请求。

![](/assets/images/posts/loadbalance/loadbalance-3.png)

**客户端是如何把请求发送到应用服务器的**

![](/assets/images/posts/loadbalance/loadbalance-4.png)

客户端把请求发送到应用服务器有如下几个步骤：

1. 客户端请求 URL 给 DNS。
2. DNS 将 URL 转化成对应的 IP。
3. 通过 IP 找到服务器。
4. 服务器接受到请求的报文，转交给接入层处理，接入层由于采用了硬件负载均衡器，所以能够扛住大数据量。
5. 接入层把报文再次转交给代理层（并发 5W），代理层的 Nginx 收到报文再根据反向代理的策略发送给上游服务器（应用服务器）

本文主要介绍基于nginx实现的负载均衡

# 负载均衡算法
## 随机(Random)

这种方法会将收到的请求随机分配到服务器集群中的每台机器

## 轮循(Round Robin)

这种方法会将收到的请求循环分配到服务器集群中的每台机器，即有效服务器。如果使用这种方式，所有的标记进入虚拟服务的服务器应该有相近的资源容量以及负载形同的应用程序。如果所有的服务器有相同或者相近的性能那么选择这种方式会使服务器负载形同。基于这个前提，轮循调度是一个简单而有效的分配请求的方式。然而对于服务器不同的情况，选择这种方式就意味着能力比较弱的服务器也会在下一轮循环中接受轮循，即使这个服务器已经不能再处理当前这个请求了。这可能导致能力较弱的服务器超载

![](/assets/images/posts/loadbalance/loadbalance-5.png)

```
upstream my_service {
	  server 192.168.3.8:9000;
	  server 192.168.3.8:9001;
}
```

## 加权轮循(Weighted Round Robin)

这种算法解决了简单轮循调度算法的缺点：传入的请求按顺序被分配到集群中服务器，但是会考虑提前为每台服务器分配的权重。管理员只是简单的通过服务器的处理能力来定义各台服务器的权重。例如，能力最强的服务器A给的权重是100，同时能力最低的服务器给的权重是50。这意味着在服务器B接收到第一个请求之前前，服务器A会连续的接受到2个请求，以此类推。

![](/assets/images/posts/loadbalance/loadbalance-6.png)

```
upstream my_service_weight {
	  server 192.168.3.8:9000 weight=1;
	  server 192.168.3.8:9001 weight=2;
}
```

算法逻辑

For edge case weights like { 5, 1, 1 } we now produce { a, a, b, a, c, a, a }
sequence instead of { c, b, a, a, a, a, a } produced previously.

Algorithm is as follows: on each peer selection we increase current_weight
of each eligible peer by its weight, select peer with greatest current_weight
and reduce its current_weight by total number of weight points distributed
among peers.

In case of { 5, 1, 1 } weights this gives the following sequence of
current_weight's:

     a  b  c
     0  0  0  (initial state)
    
     5  1  1  (a selected)
    -2  1  1
    
     3  2  2  (a selected)
    -4  2  2
    
     1  3  3  (b selected)
     1 -4  3
    
     6 -3  4  (a selected)
    -1 -3  4
    
     4 -2  5  (c selected)
     4 -2 -2
    
     9 -1 -1  (a selected)
     2 -1 -1
    
     7  0  0  (a selected)
     0  0  0

To preserve weight reduction in case of failures the effective_weight
variable was introduced, which usually matches peer's weight, but is
reduced temporarily on peer failures.

## 最少连接数(Least Connection)

以上两种方法都没有考虑的是系统不能识别在给定的时间里保持了多少连接。因此可能发生，服务器B收到的连接比服务器A少但是它已经超载，因为服务器B上的用户打开连接持续的时间更长。这就是说连接数即服务器的负载是累加的。这种潜在的问题可以通过“最少连接数”算法来避免：传入的请求是根据每台服务器当前所打开的连接数来分配的。即活跃连接数最少的服务器会自动接收下一个传入的请求。基本上和简单轮询的原则相同：所有拥有虚拟服务的服务器资源容量应该相近。值得注意的是，在流量率低的配置环境中，各服务器的流量并不是相同的，会优先考虑第一台服务器。这是因为，如果所有的服务器是相同的，那么第一个服务器优先，直到第一台服务器有连续的活跃流量，否则总是会优先选择第一台服务器。

![](/assets/images/posts/loadbalance/loadbalance-7.png)

```
upstream my_service_least_conn {
	  least_conn;
	  server 192.168.3.8:9000;
	  server 192.168.3.8:9001;
}
```

## 加权最少连接(Weighted Least Connection)

如果服务器的资源容量各不相同，那么“加权最少连接”方法更合适：由管理员根据服务器情况定制的权重所决定的活跃连接数一般提供了一种对服务器非常平衡的利用，因为他它借鉴了最少连接和权重两者的优势。通常，这是一个非常公平的分配方式，因为它使用了连接数和服务器权重比例;集群中比例最低的服务器自动接收下一个请求。但是请注意，在低流量情况中使用这种方法时，请参考“最小连接数”方法中的注意事项。

## 最少连接数慢启动时间(Least Connection Slow Start Time)

对最少连接数和带权重的最小连接数调度方法来说，当一个服务器刚加入线上环境是，可以为其配置一个时间段，在这段时间内连接数是有限制的而且是缓慢增加的。这为服务器提供了一个‘过渡时间’以保证这个服务器不会因为刚启动后因为分配的连接数过多而超载。

## 基于代理的自适应负载均衡(Agent Based Adaptive Balancing)

除了上述方法之外，负载主机包含一个自适用逻辑用来定时监测服务器状态和该服务器的权重。对于非常强大的“基于代理的自适应负载均衡”方法来说，负载主机以这种方式来定时检测所有服务器负载情况：每台服务器都必须提供一个包含文件，这个文件包含一个0~99的数字用来标明改服务器的实际负载情况(0=空前，99=超载，101=失败，102=管理员禁用)，而服务器同构http get方法来获取这个文件;同时对集群中服务器来说，以二进制文件形式提供自身负载情况也是该服务器工作之一，然而，并没有限制服务器如何计算自身的负载情况。根据服务器整体负载情况，有两种策略可以选择：在常规的操作中，调度算法通过收集的服务器负载值和分配给该服务器的连接数的比例计算出一个权重比例。因此，如果一个服务器负载过大，权重会通过系统透明的作重新调整。和加权轮循调度方法一样，不正确的分配可以被记录下来使得可以有效的为不同服务器分配不同的权重。然而，在流量非常低的环境下，服务器报上来的负载值将不能建立一个有代表性的样本;那么基于这些值来分配负载的话将导致失控以及指令震荡。因此，在这种情况下更合理的做法是基于静态的权重比来计算负载分配。当所有服务器的负载低于管理员定义的下限时，负载主机就会自动切换为加权轮循方式来分配请求;如果负载大于管理员定义的下限，那么负载主机又会切换回自适应方式。

## 固定权重(Fixed Weighted)

最高权重只有在其他服务器的权重值都很低时才使用。然而，如果最高权重的服务器下降，则下一个最高优先级的服务器将为客户端服务。这种方式中每个真实服务器的权重需要基于服务器优先级来配置。

## 加权响应(Weighted Response)

流量的调度是通过加权轮循方式。加权轮循中所使用的权重是根据服务器有效性检测的响应时间来计算。每个有效性检测都会被计时，用来标记它响应成功花了多长时间。但是需要注意的是，这种方式假定服务器心跳检测是基于机器的快慢，但是这种假设也许不总是能够成立。所有服务器在虚拟服务上的响应时间的总和加在一起，通过这个值来计算单个服务物理服务器的权重;这个权重值大约每15秒计算一次。

![](/assets/images/posts/loadbalance/loadbalance-8.png)

## 源IP哈希(Source IP Hash)

这种方式通过生成请求源IP的哈希值，并通过这个哈希值来找到正确的真实服务器。这意味着对于同一主机来说他对应的服务器总是相同。使用这种方式，你不需要保存任何源IP。但是需要注意，这种方式可能导致服务器负载不平衡。

```
upstream my_service_ip_hash {
	  ip_hash;
	  server 192.168.3.8:9000;
	  server 192.168.3.8:9001;
}
```

## url哈希
按访问url的hash结果来分配请求，使每个url定向到同一个后端服务器，后端服务器为缓存时比较有效

```
upstream my_service_url_hash {
	  hash $request_uri;
	  server 192.168.3.8:9000;
	  server 192.168.3.8:9001;
}
```

# 服务层的负载均衡(权重)

> 这部分的内容基本来自于沈剑的文章，具体的地址我忘了，没找到

后端的service有可能部署在硬件条件不同的服务器上：

1. 如果对标最低配的服务器“均匀”分摊负载，高配的服务器的利用率不足；
2. 如果对标最高配的服务器“均匀”分摊负载，低配的服务器可能会扛不住；

## 静态权重

![](/assets/images/posts/loadbalance/loadbalance-9.png)

调用方通过连接池组件访问下游service，通常采用“随机”的方式返回连接，以保证下游service访问的均衡性。

要打破这个随机性，最容易想到的方法，只要为每个下游service设置一个“权重”，代表service的处理能力，来调整访问到每个service的概率，例如：

假设service-ip1，service-ip2，service-ip3的处理能力相同，可以设置weight1=1，weight2=1，weight3=1，这样三个service连接被获取到的概率分别就是1/3，1/3，1/3，能够保证均衡访问。

假设service-ip1的处理能力是service-ip2，service-ip3的处理能力的2倍，可以设置weight1=2，weight2=1，weight3=1，这样三个service连接被获取到的概率分别就是2/4，1/4，1/4，能够保证处理能力强的service分别到等比的流量，不至于资源浪费。

使用nginx做反向代理与负载均衡，就有类似的机制。

这个方案的优点是：简单，能够快速的实现异构服务器的负载均衡。

缺点也很明显：这个权重是固定的，无法自适应动态调整，而很多时候，服务器的处理能力是很难用一个固定的数值量化。

## 动态权重

提问：通过什么来标识一个service的处理能力呢？

回答：其实一个service能不能处理得过来，能不能响应得过来，应该由调用方说了算。调用服务，快速处理了，处理能力跟得上；调用服务，处理超时了，处理能力很有可能跟不上了。

动态权重设计

1. 用一个动态权重来标识每个service的处理能力，默认初始处理能力相同，即分配给每个service的概率相等；
2. 每当service成功处理一个请求，认为service处理能力足够，权重动态+1
3. 每当service超时处理一个请求，认为service处理能力可能要跟不上了，权重动态-10（权重下降会更快）
4. 为了方便权重的处理，可以把权重的范围限定为[0, 100]，把权重的初始值设为60分

举例说明：

假设service-ip1，service-ip2，service-ip3的动态权重初始值weight1=weight2=weight3=60，刚开始时，请求分配给这3台service的概率分别是60/180，60/180，60/180，即负载是均衡的。

随着时间的推移，处理能力强的service成功处理的请求越来越多，处理能力弱的service偶尔有超时，随着动态权重的增减，权重可能变化成了weight1=100，weight2=60，weight3=40，那么此时，请求分配给这3台service的概率分别是100/200，60/200，40/200，即处理能力强的service会被分配到更多的流量。

# 参考资料

https://mp.weixin.qq.com/s/4GuAT1TncctCdPIyK2bGWQ