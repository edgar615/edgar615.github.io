---
layout: post
title: 负载均衡
date: 2020-04-15
categories:
    - 分布式
comments: true
permalink: loadbalance.html
---

为了解决单点故障，保证应用程序的高可用性和性能，我们可以采取冗余的方式，将相同的应用部署多个副本，然后使用负载均衡器接受用户的请求，将请求分发给后端的应用服务器。

负载均衡（Load Balance），意思是将负载（工作任务，访问请求）进行平衡、分摊到多个操作单元（服务器，组件）上进行执行。是解决高性能，单点故障（高可用），扩展性（水平伸缩）的终极解决方案。

# 1. 原理
系统的扩展可分为纵向（垂直）扩展和横向（水平）扩展。纵向扩展，是从单机的角度通过增加硬件处理能力，比如CPU处理能力，内存容量，磁盘等方面，实现服务器处理能力的提升，不能满足大型分布式系统（网站），大流量，高并发，海量数据的问题。因此需要采用横向扩展的方式，通过添加机器来满足大型网站服务的处理能力。比如：一台机器不能满足，则增加两台或者多台机器，共同承担访问压力。这就是典型的集群和负载均衡架构：如下图：

```
						          +-------------+ 
			+-------------+ ------>   |     应用A   |
			|             |           +-------------+ 
	------>	| 负载均衡器  |
			|             |  		  +-------------+ 
			+-------------+	------>   |     应用B   |
									  +-------------+ 
```

负载均衡的作用：

1. 解决并发压力，提高应用处理性能（增加吞吐量，加强网络处理能力）；
2. 提供故障转移，实现高可用；
3. 通过添加或减少服务器数量，提供网站伸缩性（扩展性）；
4. 安全防护；（负载均衡设备上做一些过滤，黑白名单等处理）

# 2. 硬件负载均衡和软件负载均衡

谈到负载均衡，大家都会想到 Nginx，通常我们会用它做应用服务的负载均衡。

一般它的并发量在 5W 左右，如果并发量再高就需要做 Nginx 的集群了。但 Nginx 之上还有一层负载均衡器，是它把网络请求转发给 Nginx 的，同时还会肩负网络链路，防火墙等工作。

它就是“硬件负载均衡器”，一般安装在外部网络与内网服务器之间。比较流行的有 NetScaler，F5，Radware，Array 等产品。

![](/assets/images/posts/loadbalance/loadbalance-1.png)

相对于“硬件负载均衡器”来说，对内网服务器进行负载均衡就属于“软件负载均衡器”。例如：LVS，HAProxy，Nginx。

**硬件负载均衡工作在“接入层”，**主要任务是多链路负载均衡，防火墙负载均衡，服务器负载均衡。

**软件负载均衡工作在“代理层”，**主要任务是反向代理，缓存，数据验证等等。

![](/assets/images/posts/loadbalance/loadbalance-2.png)

硬件负载均衡在接入层获得网络请求，然后转交给软件负载均衡，用同样的方式处理返回的请求。

![](/assets/images/posts/loadbalance/loadbalance-3.png)


**客户端是如何把请求发送到应用服务器的**

![](/assets/images/posts/loadbalance/loadbalance-4.png)

客户端把请求发送到应用服务器有如下几个步骤：

1. 客户端请求 URL 给 DNS。
2. DNS 将 URL 转化成对应的 IP。
3. 通过 IP 找到服务器。
4. 服务器接受到请求的报文，转交给接入层处理，接入层由于采用了硬件负载均衡器，所以能够扛住大数据量。
5. 接入层把报文再次转交给代理层（并发 5W），代理层的 Nginx 收到报文再根据反向代理的策略发送给上游服务器（应用服务器）


# 3. 四层负载均衡和七层负载均衡

应用程序通过网络进行通信，需要不同的软件和硬件合作完成。为了将复杂的问题简化，将通信过程中的相关功能各进行分层。开放系统互连（OSI）将网络通信抽象为七层模型，


```
+-------------+ 
|    应用层   |
+-------------+
+-------------+ 
|    表示层   |
+-------------+
+-------------+ 
|    会话层   |
+-------------+
+-------------+ 
|    传输层   |
+-------------+
+-------------+ 
|    网络层   |
+-------------+
+-------------+ 
|  数据链路层  |
+-------------+
+-------------+ 
|    物理层   |
+-------------+
```

按照OSI模型定义的层级，将负载均衡器分为**四层负载均衡**和**七层负载均衡**。

四层负载均衡工作在传输层。传输层负责处理消息的传递而不考虑消息的内容。HTTP协议使用了传输控制协议（TCP），故四层负载均衡器简单地将网络数据包转发到上游服务器和转发上游服务器的数据包，不检查数据包的内容。四层负载均衡器可以通过检查TCP流中的前几个数据包来做出有限的路由决策。

七层负载均衡器工作在应用层。HTTP就是工作在第七层的协议。第七层的负载均衡器的工作方式比第四层的负载均衡器更复杂，它会截取流量，读取其中的信息，并根据消息的内容（如URL、cookie）作出负载均衡的决策。然后，它与选定的上游服务器建立新的TCP连接，并将请求写入服务器。

与七层负载均衡相比，四层负载均衡需要的计算量更小；在IT技术发展的早期，客户端和服务器之间的交互也不如现在复杂，所以当时四层负载均衡是一种更流行的流量处理方法。遵循摩尔定理，硬件在性能提高的同时价格也降低，现在的CPU和内存已经足够便宜，大多数的情况下，四层负载均衡的性能优势可以忽略不计。

七层负载均衡在时间和计算量方面比第四层更加昂贵，不过它可以提供更丰富的功能，从而带来更高的整体效率。比如七层负载均衡器可以确定客户端请求的数据类型，从而不必在所有的服务器上复制相同的数据。

LVS(Linux虚拟服务)是工作在第四层的负载均衡软件，在各个主要用来构建高可用的网络服务，比如Web服务、电子邮件服务、媒体服务、语音服务等。

> 再工作中没接触过LVS

Nginx既可以作为四层负载均衡器使用，也可以作为七层负载均衡器使用。这里将主要介绍七层负载均衡的使用。

Nginx最简单的负载均衡配置如下

```
# http协议块
http {
    # 上游配置
    upstream myapp1 {
        server 192.168.1.101;
        server 192.168.1.102;
        server 192.168.1.103;
    }
    # server块配置
    server {
        # 监听端口
        listen 80;
        # location配置
        location / {
            proxy_pass http://myapp1;
        }
    }
}
```

Nginx的代理支持HTTP、HTTPS、FastCGI、uwsgi、SCGI、memcached和gRPC协议。

# 4. 负载均衡算法
## 4.1. 随机(Random)

这种方法会将收到的请求随机分配到服务器集群中的每台机器

## 4.2. 轮循(Round Robin)

这种方法会将收到的请求循环分配到服务器集群中的每台机器，即有效服务器。如果使用这种方式，所有的标记进入虚拟服务的服务器应该有相近的资源容量以及负载形同的应用程序。如果所有的服务器有相同或者相近的性能那么选择这种方式会使服务器负载形同。基于这个前提，轮循调度是一个简单而有效的分配请求的方式。然而对于服务器不同的情况，选择这种方式就意味着能力比较弱的服务器也会在下一轮循环中接受轮循，即使这个服务器已经不能再处理当前这个请求了。这可能导致能力较弱的服务器超载

![](/assets/images/posts/loadbalance/loadbalance-5.png)

```
upstream my_service {
	  server 192.168.3.8:9000;
	  server 192.168.3.8:9001;
}
```

Nginx无法保证同一客户端每次都会请求到同一个服务器。

## 4.3. 加权轮循(Weighted Round Robin)

这种算法解决了简单轮循调度算法的缺点：传入的请求按顺序被分配到集群中服务器，但是会考虑提前为每台服务器分配的权重。管理员只是简单的通过服务器的处理能力来定义各台服务器的权重。例如，能力最强的服务器A给的权重是100，同时能力最低的服务器给的权重是50。这意味着在服务器B接收到第一个请求之前前，服务器A会连续的接受到2个请求，以此类推。

![](/assets/images/posts/loadbalance/loadbalance-6.png)

```
upstream my_service_weight {
	  server 192.168.3.8:9000 weight=1;
	  server 192.168.3.8:9001 weight=2;
}
```

Nginx无法保证同一客户端每次都会请求到同一个服务器。


算法逻辑

For edge case weights like { 5, 1, 1 } we now produce { a, a, b, a, c, a, a }
sequence instead of { c, b, a, a, a, a, a } produced previously.

Algorithm is as follows: on each peer selection we increase current_weight
of each eligible peer by its weight, select peer with greatest current_weight
and reduce its current_weight by total number of weight points distributed
among peers.

In case of { 5, 1, 1 } weights this gives the following sequence of
current_weight's:

     a  b  c
     0  0  0  (initial state)
    
     5  1  1  (a selected)
    -2  1  1
    
     3  2  2  (a selected)
    -4  2  2
    
     1  3  3  (b selected)
     1 -4  3
    
     6 -3  4  (a selected)
    -1 -3  4
    
     4 -2  5  (c selected)
     4 -2 -2
    
     9 -1 -1  (a selected)
     2 -1 -1
    
     7  0  0  (a selected)
     0  0  0

To preserve weight reduction in case of failures the effective_weight
variable was introduced, which usually matches peer's weight, but is
reduced temporarily on peer failures.

## 4.4. 最少连接数(Least Connection)

以上两种方法都没有考虑的是系统不能识别在给定的时间里保持了多少连接。因此可能发生，服务器B收到的连接比服务器A少但是它已经超载，因为服务器B上的用户打开连接持续的时间更长。这就是说连接数即服务器的负载是累加的。这种潜在的问题可以通过“最少连接数”算法来避免：传入的请求是根据每台服务器当前所打开的连接数来分配的。即活跃连接数最少的服务器会自动接收下一个传入的请求。基本上和简单轮询的原则相同：所有拥有虚拟服务的服务器资源容量应该相近。值得注意的是，在流量率低的配置环境中，各服务器的流量并不是相同的，会优先考虑第一台服务器。这是因为，如果所有的服务器是相同的，那么第一个服务器优先，直到第一台服务器有连续的活跃流量，否则总是会优先选择第一台服务器。

![](/assets/images/posts/loadbalance/loadbalance-7.png)

```
upstream my_service_least_conn {
	  least_conn;
	  server 192.168.3.8:9000;
	  server 192.168.3.8:9001;
}
```

Nginx无法保证同一客户端每次都会请求到同一个服务器。

## 4.5. 加权最少连接(Weighted Least Connection)

如果服务器的资源容量各不相同，那么“加权最少连接”方法更合适：由管理员根据服务器情况定制的权重所决定的活跃连接数一般提供了一种对服务器非常平衡的利用，因为他它借鉴了最少连接和权重两者的优势。通常，这是一个非常公平的分配方式，因为它使用了连接数和服务器权重比例;集群中比例最低的服务器自动接收下一个请求。但是请注意，在低流量情况中使用这种方法时，请参考“最小连接数”方法中的注意事项。

## 4.6. 最少连接数慢启动时间(Least Connection Slow Start Time)

对最少连接数和带权重的最小连接数调度方法来说，当一个服务器刚加入线上环境是，可以为其配置一个时间段，在这段时间内连接数是有限制的而且是缓慢增加的。这为服务器提供了一个‘过渡时间’以保证这个服务器不会因为刚启动后因为分配的连接数过多而超载。

## 4.7. 基于代理的自适应负载均衡(Agent Based Adaptive Balancing)

除了上述方法之外，负载主机包含一个自适用逻辑用来定时监测服务器状态和该服务器的权重。对于非常强大的“基于代理的自适应负载均衡”方法来说，负载主机以这种方式来定时检测所有服务器负载情况：每台服务器都必须提供一个包含文件，这个文件包含一个0~99的数字用来标明改服务器的实际负载情况(0=空前，99=超载，101=失败，102=管理员禁用)，而服务器同构http get方法来获取这个文件;同时对集群中服务器来说，以二进制文件形式提供自身负载情况也是该服务器工作之一，然而，并没有限制服务器如何计算自身的负载情况。根据服务器整体负载情况，有两种策略可以选择：在常规的操作中，调度算法通过收集的服务器负载值和分配给该服务器的连接数的比例计算出一个权重比例。因此，如果一个服务器负载过大，权重会通过系统透明的作重新调整。和加权轮循调度方法一样，不正确的分配可以被记录下来使得可以有效的为不同服务器分配不同的权重。然而，在流量非常低的环境下，服务器报上来的负载值将不能建立一个有代表性的样本;那么基于这些值来分配负载的话将导致失控以及指令震荡。因此，在这种情况下更合理的做法是基于静态的权重比来计算负载分配。当所有服务器的负载低于管理员定义的下限时，负载主机就会自动切换为加权轮循方式来分配请求;如果负载大于管理员定义的下限，那么负载主机又会切换回自适应方式。

## 4.8. 加权响应(Weighted Response)

流量的调度是通过加权轮循方式。加权轮循中所使用的权重是根据服务器有效性检测的响应时间来计算。每个有效性检测都会被计时，用来标记它响应成功花了多长时间。但是需要注意的是，这种方式假定服务器心跳检测是基于机器的快慢，但是这种假设也许不总是能够成立。所有服务器在虚拟服务上的响应时间的总和加在一起，通过这个值来计算单个服务物理服务器的权重;这个权重值大约每15秒计算一次。

![](/assets/images/posts/loadbalance/loadbalance-8.png)

## 4.9. 源IP哈希(Source IP Hash)

这种方式通过生成请求源IP的哈希值，并通过这个哈希值来找到正确的真实服务器。这意味着对于同一主机来说他对应的服务器总是相同。使用这种方式，你不需要保存任何源IP。但是需要注意，这种方式可能导致服务器负载不平衡。

```
upstream my_service_ip_hash {
	  ip_hash;
	  server 192.168.3.8:9000;
	  server 192.168.3.8:9001;
}
```

## 4.10. url哈希
按访问url的hash结果来分配请求，使每个url定向到同一个后端服务器，后端服务器为缓存时比较有效

```
upstream my_service_url_hash {
	  hash $request_uri;
	  server 192.168.3.8:9000;
	  server 192.168.3.8:9001;
}
```

# 5. 参考资料

https://mp.weixin.qq.com/s/4GuAT1TncctCdPIyK2bGWQ

https://mp.weixin.qq.com/s/5K36wNsZjFnuQMfuFcNv8Q
