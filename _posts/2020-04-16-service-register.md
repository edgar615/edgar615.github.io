---
layout: post
title: 服务注册与发现
date: 2020-04-16
categories:
    - 分布式
comments: true
permalink: service-register.html
---

服务注册中心是微服务架构最基础也是最重要的组件之一，服务注册中心本质上是为了解耦服务提供者和服务消费者。对于任何一个微服务，原则上都应存在或者支持多个提供者，这是由微服务的分布式属性决定的。更进一步，为了支持弹性扩缩容特性，一个微服务的提供者的数量和分布往往是动态变化的，也是无法预先确定的。因此，原本在单体应用阶段常用的静态LB机制就不再适用了，需要引入额外的组件来管理微服务提供者的注册与发现，而这个组件就是服务注册中心。

服务注册中心主要是解决什么问题：

- **服务注册：** 实例将自身服务信息注册到注册中心，这部分信息包括服务的主机 IP 和服务的 Port，以及暴露服务自身状态和访问协议信息等。
- **服务发现：** 实例请求注册中心所依赖的服务信息，服务实例通过注册中心，获取到注册到其中的服务实例的信息，通过这些信息去请求它们提供的服务。

![](/assets/images/posts/service-register/service-register-1.png)

# 1. 为什么不使用 DNS？

如果我们用 DNS 来实现服务发现，所有的服务提供者节点都配置在了同一个域名下，调用方的确可以通过 DNS 拿到随机的一个服务提供者的 IP，并与之建立长连接，这看上去并没有太大问题，但在我们业界为什么很少用到这种方案呢？
现在可以思考这样两个问题：

- 如果这个 IP 端口下线了，服务调用者能否及时摘除服务节点呢？
- 如果在之前已经上线了一部分服务节点，这时我突然对这个服务进行扩容，那么新上线的服务节点能否及时接收到流量呢？

这两个问题的答案都是：“不能”。

这两个问题的答案都是：“不能”。这是因为为了提升性能和减少 DNS 服务的压力，DNS 采取了多级缓存机制。

dns轮询只能扩展性能，不能保证高可用

# 2. 实现
了解了注册中心的原理之后，我们来谈谈注册中心的实现。

## 2.1. Zookeeper
Zookeeper 用来做服务注册中心，主要是因为它具有节点变更通知功能，只要客户端监听相关服务节点，服务节点的所有变更，都能及时的通知到监听客户端，这样作为调用方只要使用 Zookeeper 的客户端就能实现服务节点的订阅和变更通知功能了，非常方便。

Zookeeper 保证 CP，即任何时刻对 Zookeeper 的访问请求能得到一致性的数据结果，同时系统对网络分割具备容错性，但是它不能保证每次服务的可用性。在使用 Zookeeper 获取服务列表时，如果 ZK 正在选举或者 ZK 集群中半数以上的机器不可用，那么将无法获取数据。所以说，ZK 不能保证服务可用性。

## 2.2. Eureka 

![](/assets/images/posts/service-register/service-register-2.png)

Eureka 保证 AP，Eureka 在设计时优先保证可用性，每一个节点都是平等的。

一部分节点挂掉不会影响到正常节点的工作，不会出现类似 ZK 的选举 Leader 的过程，客户端发现向某个节点注册或连接失败，会自动切换到其他的节点。

只要有一台 Eureka 存在，就可以保证整个服务处在可用状态，只不过有可能这个服务上的信息并不是最新的信息。

数据不一致性在注册服务中会给 Eureka 带来的问题，无非就是某一个节点被注册的服务多，某个节点注册的服务少，在某一个瞬间可能导致某些 IP 节点被调用数多，某些 IP 节点调用数少的问题。也有可能存在一些本应该被删除而没被删除的脏数据。

![](/assets/images/posts/service-register/service-register-3.png)

## 2.3. Consul

如果要基于Consul作为服务注册中心，那么首先必须在每个服务所在的机器上部署一个Consul Agent，作为一个服务所在机器的代理。

然后还得在多台机器上部署Consul Server，这就是核心的服务注册中心。

这个Consul Agent可以用来收集你的服务信息然后发送给Consul Server，还会对你的服务不停的发送请求检查他是否健康。

然后你要发现别的服务的时候，Consul Agent也会帮你转发请求给Consul Server，查询其他服务所在机器。

Consul Server一般要求部署3~5台机器，以保证高可用以及数据一致性。

他们之间会自动实现数据同步，而且Consul Server集群会自动选举出一台机器作为leader，其他的Consul Server就是follower。

![](/assets/images/posts/service-register/service-register-4.png)

Consul基于Raft协议来实现CP，解决一致性问题

我在工作中选用了consul作为服务主从中心

- 最小化对已有应用的侵入性，这也是贯穿我们整个微服务化改造的原则之一
- 降低运维的复杂度，Consul Agent既可以运行在服务器模式，又可以运行在客户端模式 

# 3. 健康检查

zookeeper、Eureka采用集中式的心跳机制，是让各个服务都必须每隔一定时间发送心跳到Eureka Server。如果一段时间没收到心跳，那么就认为这个服务宕机了。

但是这种集中式的心跳机制会对Eureka Server造成较大的心跳请求压力，实际上平时Eureka Server接收最多的请求之一就是成千上万服务发送过来的心跳请求。

Consul基于Agent实现的分布式健康检查机制，可以大幅度的减小Server端的压力。每个机器上的Consul Agent会不断的发送请求检查服务是否健康，是否宕机。如果服务宕机了，那么就会通知Consul Server。

在使用spring-cloud-consul实现服务注册时，发现无法保证注册中心能够将不可用的或者下线的服务节点信息从注册中心摘除。(服务为不可用，但是一直存在)

> 当前大多开源实现使用的是 shutdownHook 来完成，当服务进程推出时，从注册中心删除相关的服务节点信息的工作。了解 shutdownHook 应该知道，依赖 shutdownHook 是不靠谱的。如果进程被 Kill -9，或者进程异常退出等都不会触发shutdownHook的执行，也就是说会导致服务注册信息残留在注册中心。所以还需要其他方式来保证注册中心能够将不可用的或者下线的服务节点信息从注册中心摘除。

为了解决服务节点摘除问题，需要引入第三方探测节点，来探测当前服务节点是否可用，如果不可用可以直接修改注册中心服务节点状态信息，或者直接删除服务节点的注册中心，另外在服务节点重新可用时，还需要重新将服务节点状态信息更新，或者重新写入服务节点信息

# 4. 平滑发布

当服务提供方机器需要发布时，这时如果直接发布，重启了服务提供方的服务节点，重启时注册中心服务节点信息状态会变成不可用或者直接删除了，服务调用方会收到注册中心推送的信息，这时候才禁止流量到刚发布的那台机器，其实已经晚了，已经有些请求不能正常处理了。

所以需要提前从注册中心做状态变更或者删除服务提供方节点信息，而将此过程直接加入到发布流程是最合理的，也就是发布时，优先从注册中心摘除服务节点或者变更服务节点状态信息，目的是提前告诉服务调用方，暂时先不要将流量发往该台机器，达到发布过程中流量平滑的目的。
